# -*- coding: utf-8 -*-
"""Project1 ML terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kvI2L-cbjmF4-an-itXOD-fKaw3dIxYZ

https://www.kaggle.com/datatattle/covid-19-nlp-text-classification || Here is the link
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

stopWords = set(stopwords.words('english'))

data = pd.read_csv('/content/sample_data/Corona_NLP_train.csv',encoding='latin-1')

data.head()

data = data.drop(['UserName','ScreenName','TweetAt','Location'],axis=1)

data.head()

data.info()

data.shape #3000+ data looks good

print(data.Sentiment.unique())
print(len(data.Sentiment.unique()))

MappedSentiment = {k:i for i,k in enumerate(data.Sentiment.unique())} # mapping label into integer

MappedSentiment # print the mapped label

data.Sentiment = data.Sentiment.map({'Extremely Positive':'Positive',
                                     'Extremely Negative':'Negative',
                                     'Negative':'Negative',
                                     'Positive':'Positive',
                                     'Neutral':'Neutral'}) # lets make it to 3 class only

data.Sentiment = data.Sentiment.map(MappedSentiment)

data.head(1) #looks good for sentiment

data.Sentiment.value_counts() #it looks balanced(?)

data.iloc[4]['OriginalTweet'] # we need clean it before , it's a dirty data

class Cleaning():
  def __init__(self,dataFrame):
    data=dataFrame.copy()
    data['Clean'] = self.lowerCase(data['OriginalTweet'])
    data = self.CleaningByRegex(data)
    self.data = data

  def lowerCase(self,dataFrame):
    return dataFrame.str.lower()

  def getData(self):
    return self.data

  def CleaningByRegex(self,data):
    data.Clean = data.Clean.replace(re.compile(r"(https\S+)")," ") #delete links
    data.Clean = data.Clean.replace(re.compile(r"(#\S+)")," ") #delete tag
    data.Clean = data.Clean.replace(re.compile(r"(@\S+)")," ") #delete tag
    data.Clean = data.Clean.replace(re.compile(r"[\W_]+")," ") # keeps only words
    return data

cleaningText = Cleaning(data)

cleaningText.getData().iloc[1]['OriginalTweet'] #before

cleaningText.getData().iloc[1]['Clean'] #after

dataClean = cleaningText.getData() #call the class

dataClean = dataClean.dropna().reset_index(drop=True) #drop the row where the clean data is empty

max_features = 10000
sequence_length = 40

vectorize_layer = keras.layers.TextVectorization(
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length)

vectorize_layer.adapt(dataClean['Clean'])

vectorize_layer(dataClean.iloc[25]['Clean']) #text to number, same like tokenizer

X= dataClean.Clean.map(vectorize_layer)

XData = np.zeros((X.shape[0],sequence_length),dtype=int)

for i,j in enumerate(X):
  if X.values[i].numpy().shape[0]!=0:
    XData[i] = X.values[i].numpy()

XData

dataClean.head(1)

y = pd.get_dummies(dataClean.Sentiment)

y.head(1)

from sklearn.model_selection import train_test_split

X_latih,X_test,Y_latih,Y_test = train_test_split(XData,y,test_size=0.2,random_state=40)

Y_test.head(1)

X_latih

X_test

def buildModel():
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=max_features ,output_dim=50,input_length=sequence_length),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(20, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(1e-4)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(3, activation='softmax')
  ])
  model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),metrics=['accuracy'])
  return model

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.9):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

model = buildModel()

model.summary()

earlyCallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)

num_epochs = 1000
history = model.fit(X_latih, Y_latih, batch_size=100,epochs=num_epochs,verbose=1,
                    callbacks=[callbacks,earlyCallback],validation_data=(X_test, Y_test))

"""The val accuracy doesnt improve after 5 epochs and stopped by early callback ,i guess that's the best the algorithm can reach (after hyperparameter tuning the accuracy finally reach 85%)"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','valid'], loc='upper right')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','valid'], loc='upper right')
plt.show()

"""looks kinda overfitting, but it's not pretty far so i guess it's fine

Test data
"""

dataTes = pd.read_csv('/content/sample_data/Corona_NLP_test.csv',encoding='latin-1')

dataTes.head()

dataTes = dataTes.drop(['UserName','ScreenName','TweetAt','Location'],axis=1)

dataTes.head()

dataTes.info()

dataTes.shape #3000+

dataTes.Sentiment = dataTes.Sentiment.map({'Extremely Positive':'Positive',
                                     'Extremely Negative':'Negative',
                                     'Negative':'Negative',
                                     'Positive':'Positive',
                                     'Neutral':'Neutral'}) # lets make it to 3 class only

dataTes.Sentiment = dataTes.Sentiment.map(MappedSentiment)

dataTes.head(1) #looks good for sentiment

dataTes.Sentiment.value_counts() #it looks balanced(?)

cleaningTestData = Cleaning(dataTes)

dataTestClean = cleaningTestData.getData()

XTes= dataTestClean.Clean.map(vectorize_layer)

XDataTes = np.zeros((XTes.shape[0],sequence_length),dtype=int)

for i,j in enumerate(XTes):
  if XTes.values[i].numpy().shape[0]!=0:
    XDataTes[i] = XTes.values[i].numpy()

yTes = pd.get_dummies(dataTestClean.Sentiment)

yTes.head(1)

XDataTes

model.evaluate(XDataTes,yTes,verbose=1)

"""Looks the data has been generalized by the model

in this code i use 3 set of data that are train data for training, validation data for validation in neural network and the last test data for testing


in train data i get accuracy value of 94.37%
in validation data i get accuracy value of 85.28%
in test data i get accuracy value of 84.5%

so basically i can say my model has generalized the data
because the difference of accuracy between validation and test data quite small
#CMIIW
"""